/var/spool/slurmd/job8162518/slurm_script: line 15: SLURM_SUBMIT_DIR: command not found
Running from 
[=== Module python/3.10 loaded ===]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
wandb: Currently logged in as: jana-mila (jana-mila-mila) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run hnm8riuf
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in ./wandb/run-20251119_230903-hnm8riuf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bigger_model_10k_1119_2309
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jana-mila-mila/trm-dev
wandb: üöÄ View run at https://wandb.ai/jana-mila-mila/trm-dev/runs/hnm8riuf
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name        | Type                              | Params | Mode 
--------------------------------------------------------------------------
0 | model       | TinyRecursiveReasoningModel_ACTV1 | 8.9 M  | train
1 | loss_fn     | MSELoss                           | 0      | train
2 | act_loss_fn | BCEWithLogitsLoss                 | 0      | train
--------------------------------------------------------------------------
8.9 M     Trainable params
0         Non-trainable params
8.9 M     Total params
35.662    Total estimated model params size (MB)
39        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Configuration:/nproject_name: trm-scheduling
run_name: bigger_model_10k_${now:%m%d_%H%M}
checkpoint_dir: checkpoints/
resume_from: null
batch_size: 4
lr: 0.0001
num_epochs: 1000
act_loss_weight: 0.01
epsilon: 0.5
data:
  train_problems_dir: data/train/10000/problems
  train_solutions_dir: data/train/10000/solutions
  val_problems_dir: data/val/problems
  val_solutions_dir: data/val/solutions
  num_workers: 4
model:
  trm_model:
    batch_size: ${batch_size}
    seq_len: 400
    puzzle_emb_ndim: 32
    num_puzzle_identifiers: 1
    vocab_size: 0
    puzzle_emb_len: 16
    H_cycles: 3
    L_cycles: 6
    L_layers: 4
    H_layers: 0
    hidden_size: 512
    expansion: 2.0
    num_heads: 8
    pos_encodings: rope
    halt_max_steps: 16
    halt_exploration_prob: 0.0
    no_ACT_continue: true
    forward_dtype: float32
trainer:
  max_epochs: ${num_epochs}
  accelerator: auto
  devices: 1
  log_every_n_steps: 10
  enable_checkpointing: true

Initializing DataModule...
Initializing LightningModule
TinyRecursiveModelJobShop(
  (model): TinyRecursiveReasoningModel_ACTV1(
    (inner): TinyRecursiveReasoningModel_ACTV1_Inner(
      (input_proj): CastedLinear()
      (lm_head): CastedLinear()
      (q_head): CastedLinear()
      (puzzle_emb): CastedSparseEmbedding()
      (rotary_emb): RotaryEmbedding()
      (L_level): TinyRecursiveReasoningModel_ACTV1ReasoningModule(
        (layers): ModuleList(
          (0-3): 4 x TinyRecursiveReasoningModel_ACTV1Block(
            (self_attn): Attention(
              (qkv_proj): CastedLinear()
              (o_proj): CastedLinear()
            )
            (mlp): SwiGLU(
              (gate_up_proj): CastedLinear()
              (down_proj): CastedLinear()
            )
          )
        )
      )
    )
  )
  (loss_fn): MSELoss()
  (act_loss_fn): BCEWithLogitsLoss()
)
Initializing Trainer...
Starting training...
Train samples: 7763, Val samples: 301
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  0.41it/s]Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  0.49it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training: |          | 0/? [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1940 [00:00<?, ?it/s]Epoch 0:   0%|          | 1/1940 [00:03<1:50:57,  0.29it/s]Epoch 0:   0%|          | 1/1940 [00:03<1:51:11,  0.29it/s, v_num=riuf, train_loss_step=9.47e+3]Epoch 0:   0%|          | 2/1940 [00:06<1:46:32,  0.30it/s, v_num=riuf, train_loss_step=9.47e+3]Epoch 0:   0%|          | 2/1940 [00:06<1:46:38,  0.30it/s, v_num=riuf, train_loss_step=2.52e+4]Epoch 0:   0%|          | 3/1940 [00:09<1:45:07,  0.31it/s, v_num=riuf, train_loss_step=2.52e+4]Epoch 0:   0%|          | 3/1940 [00:09<1:45:11,  0.31it/s, v_num=riuf, train_loss_step=2.83e+3]Epoch 0:   0%|          | 4/1940 [00:12<1:44:23,  0.31it/s, v_num=riuf, train_loss_step=2.83e+3]Epoch 0:   0%|          | 4/1940 [00:12<1:44:24,  0.31it/s, v_num=riuf, train_loss_step=3.33e+3]Epoch 0:   0%|          | 5/1940 [00:16<1:43:54,  0.31it/s, v_num=riuf, train_loss_step=3.33e+3]Epoch 0:   0%|          | 5/1940 [00:16<1:43:56,  0.31it/s, v_num=riuf, train_loss_step=3.35e+3]Epoch 0:   0%|          | 6/1940 [00:19<1:43:38,  0.31it/s, v_num=riuf, train_loss_step=3.35e+3]Epoch 0:   0%|          | 6/1940 [00:19<1:43:39,  0.31it/s, v_num=riuf, train_loss_step=2.11e+3]Epoch 0:   0%|          | 7/1940 [00:22<1:43:27,  0.31it/s, v_num=riuf, train_loss_step=2.11e+3]Epoch 0:   0%|          | 7/1940 [00:22<1:43:28,  0.31it/s, v_num=riuf, train_loss_step=1.98e+3]Epoch 0:   0%|          | 8/1940 [00:25<1:43:19,  0.31it/s, v_num=riuf, train_loss_step=1.98e+3]Epoch 0:   0%|          | 8/1940 [00:25<1:43:19,  0.31it/s, v_num=riuf, train_loss_step=3.58e+3]Epoch 0:   0%|          | 9/1940 [00:28<1:43:13,  0.31it/s, v_num=riuf, train_loss_step=3.58e+3]Epoch 0:   0%|          | 9/1940 [00:28<1:43:13,  0.31it/s, v_num=riuf, train_loss_step=2.09e+4]Epoch 0:   1%|          | 10/1940 [00:32<1:43:07,  0.31it/s, v_num=riuf, train_loss_step=2.09e+4]Epoch 0:   1%|          | 10/1940 [00:32<1:43:07,  0.31it/s, v_num=riuf, train_loss_step=1.16e+4]Epoch 0:   1%|          | 11/1940 [00:35<1:43:02,  0.31it/s, v_num=riuf, train_loss_step=1.16e+4]Epoch 0:   1%|          | 11/1940 [00:35<1:43:03,  0.31it/s, v_num=riuf, train_loss_step=1.6e+4] Epoch 0:   1%|          | 12/1940 [00:38<1:43:00,  0.31it/s, v_num=riuf, train_loss_step=1.6e+4]Epoch 0:   1%|          | 12/1940 [00:38<1:43:00,  0.31it/s, v_num=riuf, train_loss_step=3.73e+3]Epoch 0:   1%|          | 13/1940 [00:41<1:42:55,  0.31it/s, v_num=riuf, train_loss_step=3.73e+3]Epoch 0:   1%|          | 13/1940 [00:41<1:42:56,  0.31it/s, v_num=riuf, train_loss_step=736.0]  Epoch 0:   1%|          | 14/1940 [00:44<1:42:52,  0.31it/s, v_num=riuf, train_loss_step=736.0]Epoch 0:   1%|          | 14/1940 [00:44<1:42:52,  0.31it/s, v_num=riuf, train_loss_step=2.07e+4]Epoch 0:   1%|          | 15/1940 [00:48<1:43:07,  0.31it/s, v_num=riuf, train_loss_step=2.07e+4]Epoch 0:   1%|          | 15/1940 [00:48<1:43:07,  0.31it/s, v_num=riuf, train_loss_step=621.0]  Epoch 0:   1%|          | 16/1940 [00:51<1:43:03,  0.31it/s, v_num=riuf, train_loss_step=621.0]Epoch 0:   1%|          | 16/1940 [00:51<1:43:03,  0.31it/s, v_num=riuf, train_loss_step=2.05e+4]Epoch 0:   1%|          | 17/1940 [00:54<1:42:59,  0.31it/s, v_num=riuf, train_loss_step=2.05e+4]Epoch 0:   1%|          | 17/1940 [00:54<1:42:59,  0.31it/s, v_num=riuf, train_loss_step=1.48e+3]Epoch 0:   1%|          | 18/1940 [00:57<1:42:54,  0.31it/s, v_num=riuf, train_loss_step=1.48e+3]Epoch 0:   1%|          | 18/1940 [00:57<1:42:55,  0.31it/s, v_num=riuf, train_loss_step=1.33e+3]Epoch 0:   1%|          | 19/1940 [01:01<1:42:51,  0.31it/s, v_num=riuf, train_loss_step=1.33e+3]Epoch 0:   1%|          | 19/1940 [01:01<1:42:51,  0.31it/s, v_num=riuf, train_loss_step=4.88e+3]Epoch 0:   1%|          | 20/1940 [01:04<1:42:47,  0.31it/s, v_num=riuf, train_loss_step=4.88e+3]Epoch 0:   1%|          | 20/1940 [01:04<1:42:47,  0.31it/s, v_num=riuf, train_loss_step=3.67e+4]Epoch 0:   1%|          | 21/1940 [01:07<1:42:43,  0.31it/s, v_num=riuf, train_loss_step=3.67e+4]Epoch 0:   1%|          | 21/1940 [01:07<1:42:44,  0.31it/s, v_num=riuf, train_loss_step=6.84e+3]Epoch 0:   1%|          | 22/1940 [01:10<1:42:40,  0.31it/s, v_num=riuf, train_loss_step=6.84e+3]Epoch 0:   1%|          | 22/1940 [01:10<1:42:40,  0.31it/s, v_num=riuf, train_loss_step=3.07e+3]Epoch 0:   1%|          | 23/1940 [01:13<1:42:37,  0.31it/s, v_num=riuf, train_loss_step=3.07e+3]Epoch 0:   1%|          | 23/1940 [01:13<1:42:37,  0.31it/s, v_num=riuf, train_loss_step=2.11e+3]Epoch 0:   1%|          | 24/1940 [01:17<1:42:34,  0.31it/s, v_num=riuf, train_loss_step=2.11e+3]Epoch 0:   1%|          | 24/1940 [01:17<1:42:34,  0.31it/s, v_num=riuf, train_loss_step=1.07e+3]Epoch 0:   1%|‚ñè         | 25/1940 [01:20<1:42:31,  0.31it/s, v_num=riuf, train_loss_step=1.07e+3]Epoch 0:   1%|‚ñè         | 25/1940 [01:20<1:42:31,  0.31it/s, v_num=riuf, train_loss_step=661.0]  Epoch 0:   1%|‚ñè         | 26/1940 [01:23<1:42:28,  0.31it/s, v_num=riuf, train_loss_step=661.0]Epoch 0:   1%|‚ñè         | 26/1940 [01:23<1:42:28,  0.31it/s, v_num=riuf, train_loss_step=1.25e+4]Epoch 0:   1%|‚ñè         | 27/1940 [01:26<1:42:24,  0.31it/s, v_num=riuf, train_loss_step=1.25e+4]Epoch 0:   1%|‚ñè         | 27/1940 [01:26<1:42:25,  0.31it/s, v_num=riuf, train_loss_step=1.73e+3]Epoch 0:   1%|‚ñè         | 28/1940 [01:29<1:42:21,  0.31it/s, v_num=riuf, train_loss_step=1.73e+3]Epoch 0:   1%|‚ñè         | 28/1940 [01:29<1:42:21,  0.31it/s, v_num=riuf, train_loss_step=1.75e+3]Epoch 0:   1%|‚ñè         | 29/1940 [01:33<1:42:18,  0.31it/s, v_num=riuf, train_loss_step=1.75e+3]Epoch 0:   1%|‚ñè         | 29/1940 [01:33<1:42:18,  0.31it/s, v_num=riuf, train_loss_step=1.02e+4]Epoch 0:   2%|‚ñè         | 30/1940 [01:36<1:42:16,  0.31it/s, v_num=riuf, train_loss_step=1.02e+4]Epoch 0:   2%|‚ñè         | 30/1940 [01:36<1:42:16,  0.31it/s, v_num=riuf, train_loss_step=1.74e+4]Epoch 0:   2%|‚ñè         | 31/1940 [01:39<1:42:13,  0.31it/s, v_num=riuf, train_loss_step=1.74e+4]Epoch 0:   2%|‚ñè         | 31/1940 [01:39<1:42:13,  0.31it/s, v_num=riuf, train_loss_step=1.39e+3]Epoch 0:   2%|‚ñè         | 32/1940 [01:42<1:42:17,  0.31it/s, v_num=riuf, train_loss_step=1.39e+3]Epoch 0:   2%|‚ñè         | 32/1940 [01:42<1:42:17,  0.31it/s, v_num=riuf, train_loss_step=1.35e+3]Epoch 0:   2%|‚ñè         | 33/1940 [01:46<1:42:14,  0.31it/s, v_num=riuf, train_loss_step=1.35e+3]Epoch 0:   2%|‚ñè         | 33/1940 [01:46<1:42:14,  0.31it/s, v_num=riuf, train_loss_step=1.94e+3]Epoch 0:   2%|‚ñè         | 34/1940 [01:49<1:42:11,  0.31it/s, v_num=riuf, train_loss_step=1.94e+3]Epoch 0:   2%|‚ñè         | 34/1940 [01:49<1:42:11,  0.31it/s, v_num=riuf, train_loss_step=1.48e+4]Epoch 0:   2%|‚ñè         | 35/1940 [01:52<1:42:08,  0.31it/s, v_num=riuf, train_loss_step=1.48e+4]Epoch 0:   2%|‚ñè         | 35/1940 [01:52<1:42:08,  0.31it/s, v_num=riuf, train_loss_step=4.17e+3]Epoch 0:   2%|‚ñè         | 36/1940 [01:55<1:42:06,  0.31it/s, v_num=riuf, train_loss_step=4.17e+3]Epoch 0:   2%|‚ñè         | 36/1940 [01:55<1:42:06,  0.31it/s, v_num=riuf, train_loss_step=3.22e+3]Epoch 0:   2%|‚ñè         | 37/1940 [01:59<1:42:03,  0.31it/s, v_num=riuf, train_loss_step=3.22e+3]Epoch 0:   2%|‚ñè         | 37/1940 [01:59<1:42:03,  0.31it/s, v_num=riuf, train_loss_step=3.71e+3]Epoch 0:   2%|‚ñè         | 38/1940 [02:02<1:42:00,  0.31it/s, v_num=riuf, train_loss_step=3.71e+3]Epoch 0:   2%|‚ñè         | 38/1940 [02:02<1:42:00,  0.31it/s, v_num=riuf, train_loss_step=1e+3]   Epoch 0:   2%|‚ñè         | 39/1940 [02:05<1:41:57,  0.31it/s, v_num=riuf, train_loss_step=1e+3]Epoch 0:   2%|‚ñè         | 39/1940 [02:05<1:41:57,  0.31it/s, v_num=riuf, train_loss_step=2.84e+3]Epoch 0:   2%|‚ñè         | 40/1940 [02:08<1:41:54,  0.31it/s, v_num=riuf, train_loss_step=2.84e+3]Epoch 0:   2%|‚ñè         | 40/1940 [02:08<1:41:55,  0.31it/s, v_num=riuf, train_loss_step=1.23e+4]Epoch 0:   2%|‚ñè         | 41/1940 [02:11<1:41:52,  0.31it/s, v_num=riuf, train_loss_step=1.23e+4]Epoch 0:   2%|‚ñè         | 41/1940 [02:11<1:41:52,  0.31it/s, v_num=riuf, train_loss_step=2.61e+3]Epoch 0:   2%|‚ñè         | 42/1940 [02:15<1:41:50,  0.31it/s, v_num=riuf, train_loss_step=2.61e+3]Epoch 0:   2%|‚ñè         | 42/1940 [02:15<1:41:50,  0.31it/s, v_num=riuf, train_loss_step=6.25e+4]Epoch 0:   2%|‚ñè         | 43/1940 [02:18<1:41:47,  0.31it/s, v_num=riuf, train_loss_step=6.25e+4]Epoch 0:   2%|‚ñè         | 43/1940 [02:18<1:41:47,  0.31it/s, v_num=riuf, train_loss_step=1.61e+3]Epoch 0:   2%|‚ñè         | 44/1940 [02:21<1:41:45,  0.31it/s, v_num=riuf, train_loss_step=1.61e+3]Epoch 0:   2%|‚ñè         | 44/1940 [02:21<1:41:45,  0.31it/s, v_num=riuf, train_loss_step=2.01e+4]Epoch 0:   2%|‚ñè         | 45/1940 [02:24<1:41:42,  0.31it/s, v_num=riuf, train_loss_step=2.01e+4]Epoch 0:   2%|‚ñè         | 45/1940 [02:24<1:41:42,  0.31it/s, v_num=riuf, train_loss_step=3.15e+3]Epoch 0:   2%|‚ñè         | 46/1940 [02:28<1:41:40,  0.31it/s, v_num=riuf, train_loss_step=3.15e+3]Epoch 0:   2%|‚ñè         | 46/1940 [02:28<1:41:40,  0.31it/s, v_num=riuf, train_loss_step=2.84e+3]Epoch 0:   2%|‚ñè         | 47/1940 [02:31<1:41:38,  0.31it/s, v_num=riuf, train_loss_step=2.84e+3]Epoch 0:   2%|‚ñè         | 47/1940 [02:31<1:41:38,  0.31it/s, v_num=riuf, train_loss_step=5.01e+3]Epoch 0:   2%|‚ñè         | 48/1940 [02:34<1:41:35,  0.31it/s, v_num=riuf, train_loss_step=5.01e+3]Epoch 0:   2%|‚ñè         | 48/1940 [02:34<1:41:35,  0.31it/s, v_num=riuf, train_loss_step=1.29e+4]Epoch 0:   3%|‚ñé         | 49/1940 [02:38<1:41:37,  0.31it/s, v_num=riuf, train_loss_step=1.29e+4]Epoch 0:   3%|‚ñé         | 49/1940 [02:38<1:41:37,  0.31it/s, v_num=riuf, train_loss_step=1.97e+4]Epoch 0:   3%|‚ñé         | 50/1940 [02:41<1:41:35,  0.31it/s, v_num=riuf, train_loss_step=1.97e+4]Epoch 0:   3%|‚ñé         | 50/1940 [02:41<1:41:35,  0.31it/s, v_num=riuf, train_loss_step=8.93e+3]Epoch 0:   3%|‚ñé         | 51/1940 [02:44<1:41:33,  0.31it/s, v_num=riuf, train_loss_step=8.93e+3]Epoch 0:   3%|‚ñé         | 51/1940 [02:44<1:41:33,  0.31it/s, v_num=riuf, train_loss_step=7.47e+4]Epoch 0:   3%|‚ñé         | 52/1940 [02:47<1:41:30,  0.31it/s, v_num=riuf, train_loss_step=7.47e+4]Epoch 0:   3%|‚ñé         | 52/1940 [02:47<1:41:30,  0.31it/s, v_num=riuf, train_loss_step=8.04e+3]Epoch 0:   3%|‚ñé         | 53/1940 [02:50<1:41:27,  0.31it/s, v_num=riuf, train_loss_step=8.04e+3]Epoch 0:   3%|‚ñé         | 53/1940 [02:50<1:41:27,  0.31it/s, v_num=riuf, train_loss_step=2.78e+3]Epoch 0:   3%|‚ñé         | 54/1940 [02:54<1:41:25,  0.31it/s, v_num=riuf, train_loss_step=2.78e+3]Epoch 0:   3%|‚ñé         | 54/1940 [02:54<1:41:25,  0.31it/s, v_num=riuf, train_loss_step=3.48e+3]Epoch 0:   3%|‚ñé         | 55/1940 [02:57<1:41:22,  0.31it/s, v_num=riuf, train_loss_step=3.48e+3]Epoch 0:   3%|‚ñé         | 55/1940 [02:57<1:41:22,  0.31it/s, v_num=riuf, train_loss_step=3.75e+3]Epoch 0:   3%|‚ñé         | 56/1940 [03:00<1:41:19,  0.31it/s, v_num=riuf, train_loss_step=3.75e+3]Epoch 0:   3%|‚ñé         | 56/1940 [03:00<1:41:19,  0.31it/s, v_num=riuf, train_loss_step=3.65e+3]Epoch 0:   3%|‚ñé         | 57/1940 [03:03<1:41:17,  0.31it/s, v_num=riuf, train_loss_step=3.65e+3]Epoch 0:   3%|‚ñé         | 57/1940 [03:03<1:41:17,  0.31it/s, v_num=riuf, train_loss_step=3.91e+3]Epoch 0:   3%|‚ñé         | 58/1940 [03:07<1:41:14,  0.31it/s, v_num=riuf, train_loss_step=3.91e+3]Epoch 0:   3%|‚ñé         | 58/1940 [03:07<1:41:14,  0.31it/s, v_num=riuf, train_loss_step=2.29e+3]Epoch 0:   3%|‚ñé         | 59/1940 [03:10<1:41:11,  0.31it/s, v_num=riuf, train_loss_step=2.29e+3]Epoch 0:   3%|‚ñé         | 59/1940 [03:10<1:41:11,  0.31it/s, v_num=riuf, train_loss_step=1.07e+3]Epoch 0:   3%|‚ñé         | 60/1940 [03:13<1:41:09,  0.31it/s, v_num=riuf, train_loss_step=1.07e+3]Epoch 0:   3%|‚ñé         | 60/1940 [03:13<1:41:09,  0.31it/s, v_num=riuf, train_loss_step=2.61e+3]Epoch 0:   3%|‚ñé         | 61/1940 [03:16<1:41:06,  0.31it/s, v_num=riuf, train_loss_step=2.61e+3]Epoch 0:   3%|‚ñé         | 61/1940 [03:16<1:41:06,  0.31it/s, v_num=riuf, train_loss_step=2.29e+4]Epoch 0:   3%|‚ñé         | 62/1940 [03:20<1:41:03,  0.31it/s, v_num=riuf, train_loss_step=2.29e+4]Epoch 0:   3%|‚ñé         | 62/1940 [03:20<1:41:03,  0.31it/s, v_num=riuf, train_loss_step=1.01e+4]Epoch 0:   3%|‚ñé         | 63/1940 [03:23<1:41:01,  0.31it/s, v_num=riuf, train_loss_step=1.01e+4]Epoch 0:   3%|‚ñé         | 63/1940 [03:23<1:41:01,  0.31it/s, v_num=riuf, train_loss_step=2.89e+4]Epoch 0:   3%|‚ñé         | 64/1940 [03:26<1:40:58,  0.31it/s, v_num=riuf, train_loss_step=2.89e+4]Epoch 0:   3%|‚ñé         | 64/1940 [03:26<1:40:58,  0.31it/s, v_num=riuf, train_loss_step=575.0]  Epoch 0:   3%|‚ñé         | 65/1940 [03:29<1:40:55,  0.31it/s, v_num=riuf, train_loss_step=575.0]Epoch 0:   3%|‚ñé         | 65/1940 [03:29<1:40:55,  0.31it/s, v_num=riuf, train_loss_step=1.19e+4]Epoch 0:   3%|‚ñé         | 66/1940 [03:33<1:40:53,  0.31it/s, v_num=riuf, train_loss_step=1.19e+4]Epoch 0:   3%|‚ñé         | 66/1940 [03:33<1:40:53,  0.31it/s, v_num=riuf, train_loss_step=1.97e+4]Epoch 0:   3%|‚ñé         | 67/1940 [03:36<1:40:50,  0.31it/s, v_num=riuf, train_loss_step=1.97e+4]Epoch 0:   3%|‚ñé         | 67/1940 [03:36<1:40:50,  0.31it/s, v_num=riuf, train_loss_step=1.21e+3]Epoch 0:   4%|‚ñé         | 68/1940 [03:39<1:40:50,  0.31it/s, v_num=riuf, train_loss_step=1.21e+3]Epoch 0:   4%|‚ñé         | 68/1940 [03:39<1:40:50,  0.31it/s, v_num=riuf, train_loss_step=1.35e+3]Epoch 0:   4%|‚ñé         | 69/1940 [03:43<1:40:48,  0.31it/s, v_num=riuf, train_loss_step=1.35e+3]Epoch 0:   4%|‚ñé         | 69/1940 [03:43<1:40:48,  0.31it/s, v_num=riuf, train_loss_step=1.87e+3]Epoch 0:   4%|‚ñé         | 70/1940 [03:46<1:40:45,  0.31it/s, v_num=riuf, train_loss_step=1.87e+3]Epoch 0:   4%|‚ñé         | 70/1940 [03:46<1:40:45,  0.31it/s, v_num=riuf, train_loss_step=2.92e+3]Epoch 0:   4%|‚ñé         | 71/1940 [03:49<1:40:42,  0.31it/s, v_num=riuf, train_loss_step=2.92e+3]Epoch 0:   4%|‚ñé         | 71/1940 [03:49<1:40:42,  0.31it/s, v_num=riuf, train_loss_step=3.34e+3]Epoch 0:   4%|‚ñé         | 72/1940 [03:52<1:40:39,  0.31it/s, v_num=riuf, train_loss_step=3.34e+3]Epoch 0:   4%|‚ñé         | 72/1940 [03:52<1:40:39,  0.31it/s, v_num=riuf, train_loss_step=5.74e+3]Epoch 0:   4%|‚ñç         | 73/1940 [03:56<1:40:37,  0.31it/s, v_num=riuf, train_loss_step=5.74e+3]Epoch 0:   4%|‚ñç         | 73/1940 [03:56<1:40:37,  0.31it/s, v_num=riuf, train_loss_step=1.89e+4]Epoch 0:   4%|‚ñç         | 74/1940 [03:59<1:40:34,  0.31it/s, v_num=riuf, train_loss_step=1.89e+4]Epoch 0:   4%|‚ñç         | 74/1940 [03:59<1:40:34,  0.31it/s, v_num=riuf, train_loss_step=1.1e+4] Epoch 0:   4%|‚ñç         | 75/1940 [04:02<1:40:31,  0.31it/s, v_num=riuf, train_loss_step=1.1e+4]Epoch 0:   4%|‚ñç         | 75/1940 [04:02<1:40:31,  0.31it/s, v_num=riuf, train_loss_step=2.35e+3]Epoch 0:   4%|‚ñç         | 76/1940 [04:05<1:40:28,  0.31it/s, v_num=riuf, train_loss_step=2.35e+3]Epoch 0:   4%|‚ñç         | 76/1940 [04:05<1:40:28,  0.31it/s, v_num=riuf, train_loss_step=2.85e+4]Epoch 0:   4%|‚ñç         | 77/1940 [04:09<1:40:26,  0.31it/s, v_num=riuf, train_loss_step=2.85e+4]Epoch 0:   4%|‚ñç         | 77/1940 [04:09<1:40:26,  0.31it/s, v_num=riuf, train_loss_step=1.03e+3]Epoch 0:   4%|‚ñç         | 78/1940 [04:12<1:40:23,  0.31it/s, v_num=riuf, train_loss_step=1.03e+3]Epoch 0:   4%|‚ñç         | 78/1940 [04:12<1:40:23,  0.31it/s, v_num=riuf, train_loss_step=2.56e+3]Epoch 0:   4%|‚ñç         | 79/1940 [04:15<1:40:20,  0.31it/s, v_num=riuf, train_loss_step=2.56e+3]Epoch 0:   4%|‚ñç         | 79/1940 [04:15<1:40:20,  0.31it/s, v_num=riuf, train_loss_step=820.0]  Epoch 0:   4%|‚ñç         | 80/1940 [04:18<1:40:17,  0.31it/s, v_num=riuf, train_loss_step=820.0]Epoch 0:   4%|‚ñç         | 80/1940 [04:18<1:40:17,  0.31it/s, v_num=riuf, train_loss_step=1.16e+3]Epoch 0:   4%|‚ñç         | 81/1940 [04:22<1:40:14,  0.31it/s, v_num=riuf, train_loss_step=1.16e+3]Epoch 0:   4%|‚ñç         | 81/1940 [04:22<1:40:14,  0.31it/s, v_num=riuf, train_loss_step=3.53e+4]Epoch 0:   4%|‚ñç         | 82/1940 [04:25<1:40:12,  0.31it/s, v_num=riuf, train_loss_step=3.53e+4]Epoch 0:   4%|‚ñç         | 82/1940 [04:25<1:40:12,  0.31it/s, v_num=riuf, train_loss_step=3.83e+4]Epoch 0:   4%|‚ñç         | 83/1940 [04:28<1:40:09,  0.31it/s, v_num=riuf, train_loss_step=3.83e+4]Epoch 0:   4%|‚ñç         | 83/1940 [04:28<1:40:09,  0.31it/s, v_num=riuf, train_loss_step=2.21e+4]Epoch 0:   4%|‚ñç         | 84/1940 [04:31<1:40:06,  0.31it/s, v_num=riuf, train_loss_step=2.21e+4]Epoch 0:   4%|‚ñç         | 84/1940 [04:31<1:40:06,  0.31it/s, v_num=riuf, train_loss_step=2.52e+3]Epoch 0:   4%|‚ñç         | 85/1940 [04:35<1:40:03,  0.31it/s, v_num=riuf, train_loss_step=2.52e+3]Epoch 0:   4%|‚ñç         | 85/1940 [04:35<1:40:03,  0.31it/s, v_num=riuf, train_loss_step=1.71e+3]Epoch 0:   4%|‚ñç         | 86/1940 [04:38<1:40:01,  0.31it/s, v_num=riuf, train_loss_step=1.71e+3]Epoch 0:   4%|‚ñç         | 86/1940 [04:38<1:40:01,  0.31it/s, v_num=riuf, train_loss_step=1.28e+3]Epoch 0:   4%|‚ñç         | 87/1940 [04:41<1:40:01,  0.31it/s, v_num=riuf, train_loss_step=1.28e+3]Epoch 0:   4%|‚ñç         | 87/1940 [04:41<1:40:01,  0.31it/s, v_num=riuf, train_loss_step=2.31e+3]Epoch 0:   5%|‚ñç         | 88/1940 [04:45<1:39:58,  0.31it/s, v_num=riuf, train_loss_step=2.31e+3]Epoch 0:   5%|‚ñç         | 88/1940 [04:45<1:39:58,  0.31it/s, v_num=riuf, train_loss_step=2.04e+3]Epoch 0:   5%|‚ñç         | 89/1940 [04:48<1:39:55,  0.31it/s, v_num=riuf, train_loss_step=2.04e+3]Epoch 0:   5%|‚ñç         | 89/1940 [04:48<1:39:55,  0.31it/s, v_num=riuf, train_loss_step=520.0]  Epoch 0:   5%|‚ñç         | 90/1940 [04:51<1:39:52,  0.31it/s, v_num=riuf, train_loss_step=520.0]Epoch 0:   5%|‚ñç         | 90/1940 [04:51<1:39:52,  0.31it/s, v_num=riuf, train_loss_step=1.41e+3]Epoch 0:   5%|‚ñç         | 91/1srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[2025-11-19T23:14:13.495] error: *** JOB 8162518 ON cn-a009 CANCELLED AT 2025-11-19T23:14:13 DUE to SIGNAL Terminated ***
[2025-11-19T23:14:13.496] error: *** STEP 8162518.0 ON cn-a009 CANCELLED AT 2025-11-19T23:14:13 DUE to SIGNAL Terminated ***
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Wed Nov 19 23:14:13 2025
Driver Version                            : 580.95.05
CUDA Version                              : 13.0

Attached GPUs                             : 2
GPU 00000000:39:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3200881
            GPU Utilization               : 97 %
            Memory Utilization            : 44 %
            Max memory usage              : 25096 MiB
            Time                          : 0 ms
            Is Running                    : 1

GPU 00000000:B1:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes                   : None

Wed Nov 19 23:14:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Quadro RTX 8000                On  |   00000000:39:00.0 Off |                    0 |
| 41%   67C    P2            267W /  260W |   25100MiB /  46080MiB |     86%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Quadro RTX 8000                On  |   00000000:B1:00.0 Off |                    0 |
| 33%   26C    P8             34W /  260W |       4MiB /  46080MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A         3200881      C   ...m-scheduling/.venv/bin/python      25096MiB |
+-----------------------------------------------------------------------------------------+

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Wed Nov 19 23:14:19 2025
Driver Version                            : 580.95.05
CUDA Version                              : 13.0

Attached GPUs                             : 2
GPU 00000000:39:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3200881
            GPU Utilization               : 96 %
            Memory Utilization            : 43 %
            Max memory usage              : 25096 MiB
            Time                          : 317793 ms
            Is Running                    : 0

GPU 00000000:B1:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes                   : None

Wed Nov 19 23:14:19 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Quadro RTX 8000                On  |   00000000:39:00.0 Off |                    0 |
| 41%   63C    P2            119W /  260W |       1MiB /  46080MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Quadro RTX 8000                On  |   00000000:B1:00.0 Off |                    0 |
| 33%   26C    P8             34W /  260W |       1MiB /  46080MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
