{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8de4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import os\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from hydra import initialize_config_dir, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "notebook_path = Path.cwd() \n",
    "project_root = notebook_path.parent\n",
    "os.chdir(project_root)\n",
    "\n",
    "from src.datamodule import JobShopDataModule\n",
    "from src.model import TinyRecursiveModelJobShop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bf0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_config_dir = project_root / \"configs\" / \"v3\"\n",
    "with initialize_config_dir(version_base=\"1.3\", config_dir=str(abs_config_dir)):\n",
    "    # You can add overrides here if needed, e.g., overrides=[\"batch_size=32\"]\n",
    "    cfg = compose(config_name=\"default_complex.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645a9ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 problems\n",
      "There are 1000 solutions\n",
      "There are 300 problems\n",
      "There are 300 solutions\n",
      "Train samples: 1000, Val samples: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/o/oseaj/projects/trm-scheduling/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "datamodule = JobShopDataModule(\n",
    "    config=cfg, \n",
    "    batch_size=cfg.batch_size, \n",
    "    max_seq_len=cfg.model.trm_model.seq_len\n",
    ")\n",
    "\n",
    "datamodule.setup()\n",
    "dataloader = datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c042de2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyRecursiveModelJobShop(\n",
       "  (model): TinyRecursiveReasoningModel_ACTV1(\n",
       "    (inner): TinyRecursiveReasoningModel_ACTV1_Inner(\n",
       "      (input_proj): CastedLinear()\n",
       "      (cls_head): CastedLinear()\n",
       "      (q_head): CastedLinear()\n",
       "      (puzzle_emb): CastedSparseEmbedding()\n",
       "      (rotary_emb): RotaryEmbedding()\n",
       "      (L_level): TinyRecursiveReasoningModel_ACTV1ReasoningModule(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TinyRecursiveReasoningModel_ACTV1Block(\n",
       "            (self_attn): Attention(\n",
       "              (qkv_proj): CastedLinear()\n",
       "              (o_proj): CastedLinear()\n",
       "            )\n",
       "            (mlp): SwiGLU(\n",
       "              (gate_up_proj): CastedLinear()\n",
       "              (down_proj): CastedLinear()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ce_loss): CrossEntropyLoss()\n",
       "  (act_loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint_path = \"/home/mila/o/oseaj/projects/trm-scheduling/checkpoints/default_v3_complex_1222_2037/default_v3_complex_1222_2037-epoch=00-val_loss=1.5413.ckpt\"\n",
    "model = TinyRecursiveModelJobShop.load_from_checkpoint(checkpoint_path)\n",
    "model.eval()\n",
    "model.freeze()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4ffee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/o/oseaj/projects/trm-scheduling/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "B, L, K = batch['labels'].shape\n",
    "num_classes = 10\n",
    "\n",
    "carry = model.model.initial_carry(batch)\n",
    "carry.to(device)\n",
    "\n",
    "halt_max_steps = model.hparams_initial.config.halt_max_steps\n",
    "final_logits = torch.zeros(B, L, K, num_classes, device=device)\n",
    "is_finished = torch.zeros(B, dtype=torch.bool, device=device)\n",
    "with torch.no_grad():\n",
    "    for step in range(halt_max_steps):\n",
    "        # Forward pass for one step\n",
    "        carry, output = model(carry=carry, batch=batch)\n",
    "        current_logits = output[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38867996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for 16 steps...\n",
      "Done.\n",
      "Predictions shape: torch.Size([4, 400, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare Batch\n",
    "batch = next(iter(dataloader))\n",
    "batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "# 2. Initialize State\n",
    "halt_max_steps = model.hparams.config.halt_max_steps\n",
    "carry = model.model.initial_carry(batch)\n",
    "carry.to(device)\n",
    "\n",
    "print(f\"Running inference for {halt_max_steps} steps...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(halt_max_steps):\n",
    "        # Forward pass\n",
    "        # The model internally updates the 'carry' (hidden state) based on the previous step\n",
    "        carry, output = model(carry=carry, batch=batch)\n",
    "\n",
    "    # 3. Get Final Result (from the very last step)\n",
    "    final_logits = output[\"logits\"]  # Shape: (B, L, K, 10)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = final_logits.argmax(dim=-1) # Shape: (B, L, K)\n",
    "\n",
    "    # Optional: Zero out padding for cleaner inspection\n",
    "    if 'mask' in batch:\n",
    "        mask = batch['mask'].expand_as(predictions).bool()\n",
    "        predictions[~mask] = -1\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"Predictions shape:\", predictions.shape)\n",
    "# Example: Print first active task of first sample\n",
    "# print(predictions[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23656a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  3,  0],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  5,  9],\n",
       "        [ 0,  5,  9],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  5,  7],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  8,  9],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  8,  9],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  3,  0],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  7,  3],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  7],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  7,  5],\n",
       "        [ 1,  7,  9],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  7],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  8,  5],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  7],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  7],\n",
       "        [ 1,  8,  9],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  8,  7],\n",
       "        [ 1,  8,  5],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  8,  5],\n",
       "        [ 0,  8,  5],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  3,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  3,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  7,  5],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  7,  9],\n",
       "        [ 0,  7,  5],\n",
       "        [ 1,  8,  5],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  3,  0],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  8,  6],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  7,  6],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  4,  5],\n",
       "        [ 0,  5,  8],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  9],\n",
       "        [ 0,  8,  5],\n",
       "        [ 0,  8,  5],\n",
       "        [ 1,  8,  9],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  3,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  8,  7],\n",
       "        [ 1,  8,  9],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  1,  0],\n",
       "        [ 0,  3,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  5],\n",
       "        [ 0,  5,  7],\n",
       "        [ 0,  8,  7],\n",
       "        [ 0,  8,  7],\n",
       "        [ 1,  8,  9],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1],\n",
       "        [-1, -1, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb8d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = batch['labels']\n",
    "matches = (predictions == targets)\n",
    "\n",
    "# Correct if: Matches OR Target is -100 OR Padding\n",
    "ignore_mask = (targets == -100)\n",
    "is_padding  = (mask == 0)\n",
    "effective_correctness = matches | ignore_mask | is_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3c4310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_sample_correct = effective_correctness.all(dim=-1).all(dim=-1)\n",
    "is_sample_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f98409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trm-scheduling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
